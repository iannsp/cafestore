# Extraindo Dados do HTML.

O objetivo do Crawler é acessar as páginas html e extrair dados extruturados que possão ser reutilizados em outros formatos de apresentação.

Vou começar pela página principal...

```bash
# ao executar esse comando eu tenho uma cópia do html e graou o output(-o) no 
# arquivo resources/index.html
curl https://www.cafestore.com.br/ -o resources/index.html
```

...e tomar como referencia o produto Moedor de Café e procurar por ele no html resources/index.html.

![Imagem do Moedor](resources/images/index_moedor.png)

 ```html 
<div class="shelf-product" title="Moedor de Caf&#233; Manual com 7 L&#226;minas DaysBrasil Preto 30 g" data-product-id="2177" data-cat="Moedores" data-brand="DaysBrasil" data-price="R$ 379,00" itemscope="" itemtype="http://schema.org/Product">
  <figure class="shelf-product__container">
    <button class="shelf-product__wishlist js-wishlist-update">
      <i class="shelf-product__wishlist-icon icon icon-heart"></i>
    </button>
    <div class="shelf-product__image">
        <div class="hightlight">
            <p class="flag carrossel-vitrine">Carrossel Vitrine</p>
            <div class="flag flag-desconto" data-percent='0'></div>
        </div>
        <div class="discountHightLight"><p class="flag 3nodeposito">3nodeposito</p></div>
        <a title="Moedor de Caf&#233; Manual com 7 L&#226;minas DaysBrasil Preto 30 g" href="https://www.cafestore.com.br/moedor-de-cafe-manual-com-7-laminas-daysbrasil-preto-30-g-4817/p"><img src="https://cafestore.vteximg.com.br/arquivos/ids/167068-258-258/17 -1-.jpg?v=638889781378430000" width="258" height="258" alt="17 -1-" id="" /></a>
    </div>
    <figcaption class="shelf-product__info">
      <!-- Trustvox -->
      <div class="trustvox-showcase">
        <div data-trustvox-product-code="2177"></div>
      </div>
      <!-- /Trustvox -->
      <a class="shelf-product__link" title="Moedor de Caf&#233; Manual com 7 L&#226;minas DaysBrasil Preto 30 g" href="https://www.cafestore.com.br/moedor-de-cafe-manual-com-7-laminas-daysbrasil-preto-30-g-4817/p" itemprop="url">
        <h3 class="shelf-product__title" itemprop="name">Moedor de Caf&#233; Manual com 7 L&#226;minas DaysBrasil Preto 30 g</h3>
      </a>
      <div class="shelf-product__fields hide"></div>
              <span class="shelf-product__purchase" itemprop="offers" itemscope="" itemtype="http://schema.org/Offer">
          <span class="shelf-product__price">
                        <p class="shelf-product__price-best">Por: <span itemprop="price" content="379.00">R$ 379,00</span> </p>
            <meta itemprop="priceCurrency" content="BRL" />
            <link itemprop="availability" href="http://schema.org/InStock" />
          </span>
          <span class="shelf-product__action js-shelf-add-to-cart"><div class="buy-button-normal" id="2176" name="2176"><a class="buy-button-normal-a2176" href="https://www.cafestore.com.br/checkout/cart/add?sku=2176&qty=1&seller=1&sc=1&price=37900" title="Comprar">Comprar</a><input type="hidden" value="cart" class="buy-button-normal-go-to-cart-2176" /></div></span>
        </span>
          </figcaption>
  </figure>
</div> 

``` 

Esse é o html que representa um produto. Olhando outros produtos dá pra confirmar que a estrutura padrão se repete e dá pra confirmar nesse padrão para extrair dados de produto de dentro do site.

Quero fazer um teste utilizando esse html para extrair dados estruturados. Existe mais de uma maneira de fazer isso. A visual/manual, que eu já fiz ao olhar o html para saber se tinha dados que eu quero e outras como utilizar uma navegação via DomDocument, via Xml ou a que esta mais em voga, utilizar uma IA para extrair e estruturar.  

No playground  do [google ai studio](https://aistudio.google.com/) eu digito um prompt simples para extrair  o máximo de dados de maneira estruturada e ver se temos tudo que precisamos.  

O prompt:
```
extract all structure data you can from de html below:
[coloquei todo o código html acima aqui]
```

O resultado foi:


Here is the structured data extracted from the HTML, organized by category.

### 1. Product Details (General)
*   **Product Name:** Moedor de Café Manual com 7 Lâminas DaysBrasil Preto 30 g
*   **Brand:** DaysBrasil
*   **Category:** Moedores
*   **URL:** `https://www.cafestore.com.br/moedor-de-cafe-manual-com-7-laminas-daysbrasil-preto-30-g-4817/p`

### 2. Pricing & Availability
*   **Price (Display):** R$ 379,00
*   **Price (Raw Value):** 379.00
*   **Currency:** BRL
*   **Availability:** In Stock (`http://schema.org/InStock`)
*   **Promotions/Flags:**
    *   "Carrossel Vitrine"
    *   "3nodeposito"
    *   Discount Flag: 0%

### 3. Technical Identifiers (IDs)
*   **Product ID (General):** 2177
*   **SKU ID (Specific Variant):** 2176 (Found in the buy button `id` and `href`)
*   **Trustvox ID (Reviews):** 2177

### 4. Image Data
*   **Source URL:** `https://cafestore.vteximg.com.br/arquivos/ids/167068-258-258/17 -1-.jpg?v=638889781378430000`
*   **Dimensions:** 258x258
*   **Alt Text:** "17 -1-"

### 5. Purchase Data (Buy Link Analysis)
The "Buy" button contains a direct link with specific query parameters and a security token:
*   **Seller ID:** 1
*   **Sales Channel:** 1
*   **Price in Link:** 37900 (integer format)
*   **JWT Token:** `eyJhbGciOiJFUzI1NiIsImtp...` (This contains signed pricing data to prevent tampering)

---

### 6. JSON Representation
Here is all the extracted data formatted as a clean JSON object for use in code:

```json
{
  "product": {
    "name": "Moedor de Café Manual com 7 Lâminas DaysBrasil Preto 30 g",
    "id": "2177",
    "sku": "2176",
    "brand": "DaysBrasil",
    "category": "Moedores",
    "url": "https://www.cafestore.com.br/moedor-de-cafe-manual-com-7-laminas-daysbrasil-preto-30-g-4817/p",
    "image": "https://cafestore.vteximg.com.br/arquivos/ids/167068-258-258/17 -1-.jpg?v=638889781378430000"
  },
  "offer": {
    "price": 379.00,
    "currency": "BRL",
    "formattedPrice": "R$ 379,00",
    "availability": "http://schema.org/InStock",
    "sellerId": "1"
  },
  "meta": {
    "trustvoxId": "2177",
    "flags": ["Carrossel Vitrine", "3nodeposito"],
    "discountPercent": 0
  }
}
```

### 7. Schema.org Microdata (SEO View)
This is exactly how search engines (like Google) read the data based on the `itemprop` tags in the HTML:
```html


<div itemscope itemtype="http://schema.org/Product">
  <span itemprop="url">https://www.cafestore.com.br/moedor-de-cafe-manual-com-7-laminas-daysbrasil-preto-30-g-4817/p</span>
  <span itemprop="name">Moedor de Caf&#233; Manual com 7 L&#226;minas DaysBrasil Preto 30 g</span>
  <div itemprop="offers" itemscope itemtype="http://schema.org/Offer">
    <span itemprop="price" content="379.00">R$ 379,00</span>
    <meta itemprop="priceCurrency" content="BRL" />
    <link itemprop="availability" href="http://schema.org/InStock" />
  </div>
</div>
```

Nada mal para um prompt tão simples, e isso prova que é possivel utilizar o snippet de código html do produto como fonte de dados e que é possível indexar todo o conteudo do site, extrair os dados de maneira   estruturada, organizar  para permitir consulta e ter uma fonte de dados bem definida.


1. Download do site.

```bash
# Utilizando esse comando podemos baixar todo o conteúdo do site. o Comando diz 
# para navegar e gravar arquivo para todos os links encontrados de uma página 
# pra outra de maneira exaustiva.

wget --recursive --level=inf --no-clobber --page-requisites --html-extension \  
--convert-links --restrict-file-names=windows --domains=example.com --span-hosts \  
 --no-parent https://example.com
```

2. extraindo os produtos de todo o conteúdo baixado do site.

Precisamos responder a seguinte pergunta: Sera que existe um padrão que ajude a extrair os produtos do resto do html?

Como já disse anteriormente o site utiliza schema.org; O produto é um dado que esta seguindo um padrão de microdata, [Product](https://schema.org/Product), e a definição esta sendo feita em uma div, como abaixo.

```HTML
<div itemscope itemtype="http://schema.org/Product"></div>
```

Basta então executar uma regex em loop por todos os arquivos que baixei, mas olhando os arquivos encontrei outro padrão: Cada uma das páginas de produto tem o nome p.html e então posso filtrar somente pelos arquivos p.html
```bash
# localiza todos os p.html(find) e conta(wc) quantos sao. Eu baixei 600 produtos.
find ./ -name p.html | wc -l
```

Aqui utilizei PHP para executar regex no padrão PCRE (Perl Compatible Regular Expressions).

```php
exec("find ./ -name p.html", $files);                                           
function extractProduct($htmlContent){                                          
    $re = '/(<div itemscope="itemscope" itemtype="http:\/\/schema\.org\/Product">[\s\S]*?<\/div> <\/div>)/m';
    preg_match_all($re, $htmlContent, $matches, PREG_SET_ORDER, 0);             
    if (count($matches)==0)                                                     
        return null;                                                            
    return $matches[0][0];                                                      
}                                                                               
                                                                                
$products= [];                                                                  
foreach($files as $file){                                                       
    $content = file_get_contents($file);                                        
    $product = extractProduct($content);                                        
    if (!is_null($product)){                                                    
        $products[] = $product;                                               
        echo $product;                                                          
    }                                                                           
}       
``` 

Executei o script enviando o output para um arquivo txt.

```bash
php extract.php > products.txt
```

E utilizei um prompt para extrair de cada tag de produto o Json correspondente via.

```PHP
function HtmltoJson($product){
    $GEMINI_API_KEY = getenv('GEMINI_API_KEY');
    // limpar os dados de caracteres que vão quebrar a requisição.
    $product = str_replace(["\n", "\r", "\t"], " ", addslashes($product));

    $cmd = "curl \
    -X POST \
    -H \"Content-Type: application/json\" \
    \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={$GEMINI_API_KEY}\" \
    -d '{
        \"contents\": [
          {
            \"role\": \"user\",
            \"parts\": [
              {
                \"text\": \"extract the data about the product into the html as a valid one line JSON .: {$product}\"
              },
            ]
          },
        ],
        \"generationConfig\": { \"responseMimeType\": \"application/json\", \"response_mime_type\":\"application/json\"}}'";

    // executar o comando.
    
    $response = shell_exec($cmd);
    $product = (json_decode(($response)));
    return $product->candidates[0]->content->parts[0]->text; 
}

$productsJson= [];                                                              
$productsHtml = explode("----------------", file_get_contents(__DIR__."/products.txt"));

foreach($productsHtml as $product){                                                 
    $productsJson[] = HtmltoJson($product);                                            
}
  
file_put_contents(__DIR__."/products.json", json_encode( $productsJson, JSON_UNESCAPED_UNICODE|JSON_PRETTY_PRINT),  FILE_APPEND);
```

Duas coisas a destacar:

- as vezes a gemini devolve json com \\n, ou seja, json formatado e os dados precisam ser limpos. 

- A outra é que json devolvido pelas IA's na sua maioria estão em Unicode e é necessário converter para o encode desejado, que na maioria dos caso é utf-8.


